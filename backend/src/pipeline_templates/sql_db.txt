%metadata_section%import dlt
from dlt.sources.credentials import ConnectionStringCredentials
from dlt.sources.sql_database import sql_database, sql_table
from os import getenv as env
from pathlib import Path
from sys import path

#Adding root folder to allow import  from src
src_path = str(Path(__file__).parent).replace('/destinations/pipeline/%User_folder%','')
path.insert(0, src_path)
path.insert(0, src_path+'/src')

from src.services.workspace.Workspace import Workspace
from src.services.workspace.SecretManager import SecretManager
from src.utils.SQLDatabase import normalize_table_names, converts_field_type

# Bellow mapping: namespace = SqlDBComponent.namespace
namespace = %namespace%

# Bellow mapping: connection_name = SqlDBComponent.connection_name
connection_name = %connection_name%

print('connecting to secrets vault', flush=True)
SecretManager.ppline_connect_to_vault()

print(f'fetching "{connection_name}" secrets for DB connection', flush=True)
secret = SecretManager.get_db_secret(namespace, connection_name)

connection_string = secret['connection_url']

# Bellow mapping: source_database = SqlDBComponent.source_database
database_to_connect = %source_database%

credentials = ConnectionStringCredentials(connection_string)

def load_select_tables_from_db():
    dest_folder = Workspace.get_duckdb_path_on_ppline()

    %destination_settings%

    # Bellow mapping: tables = SqlDBComponent.source_tables
    tables = %source_tables%

    # Bellow mapping: tables_pk = SqlDBComponent.primary_keys
    tables_pk = %primary_keys%
    tables = normalize_table_names(secret, tables)

    # Bellow mapping: schema = SqlDBComponent.schema
    schema = %schema%

    if schema:
        source = []
        for idx in range(len(tables)):
            schema_name, table_name = tables[idx].split('.')
            db_table = sql_table(table=table_name,  credentials=credentials, schema=schema_name)
            db_table.apply_hints(primary_key=tables_pk[idx])
            source.append(converts_field_type(db_table, tables_pk[idx]))

    else:
        source = sql_database(table_names=tables, credentials=credentials)
        for idx in range(len(tables)):
            table = getattr(source, tables[idx]).apply_hints(primary_key=tables_pk[idx])
            converts_field_type(table, tables_pk[idx])

    print('Starting pipeline run', flush=True)
    info = pipeline.run(source, write_disposition='merge',%table_format%)
    print(info, flush=True)
    print('RUN_SUCCESSFULLY', flush=True)

load_select_tables_from_db()