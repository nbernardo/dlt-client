%metadata_section%import dlt
from dlt.sources.filesystem import filesystem, FileItemDict
from dlt.sources import TDataItems
from typing import Iterator, Any
import pandas as pd
%import_from_src%
"""
The pipeline run in a different process/sub-process
hence the different print statement as this is how it
will communicate with the main process about the progress
"""

# Bellow mapping: bucket_url = Bucket.bucket_url, file_glob = Bucket.file_pattern
files = filesystem(bucket_url=%bucket_url%, file_glob=%file_pattern%)

@dlt.transformer()
def read_csv_and_transform_fields(files_list: Iterator[FileItemDict]) -> Iterator[TDataItems]:
    print('Starting tranformation(s)', flush=True)
    for cur_file in files_list:
        with cur_file.open() as file:
            df = pd.read_csv(file)
            # <transformation>
            %transformation%
            # </transformation> DO NOT REMOVE THIS LINE
            yield df.to_dict(orient="records")


print('Starting the pipeline', flush=True)

try:
    # Bellow mapping: ppline_dest_table = DuckDBOutput.ppline_dest_table
    transformed_source = (files | read_csv_and_transform_fields()).with_name(%ppline_dest_table%)

    if %primary_key% != 'UNDEFINED':
        # Bellow mapping: primary_key = Bucket.primary_key
        transformed_source.apply_hints(primary_key=%primary_key%)
    
    %destination_settings%

    info = pipeline.run(transformed_source, write_disposition="merge")
    print(info, flush=True)
except Exception as err:
    print('RUNTIME_ERROR:Runtime Pipeline error')
    print(err)